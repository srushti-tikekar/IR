{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1577529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c5ec0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ltrc_yahoo/set1.train.txt') as f:\n",
    "    lines = f.readlines()\n",
    "for i in range(len(lines)):\n",
    "    lines[i]=lines[i].rstrip(lines[i][-1])\n",
    "    #print(lines[i])\n",
    "# Initialize lists to store the data\n",
    "\n",
    "train_feature_matrix = []\n",
    "train_doclist_ranges = []\n",
    "train_label_vector = []\n",
    "cc=0\n",
    "for line in lines:\n",
    "    cc=cc+1\n",
    "    if(cc>top):\n",
    "        break\n",
    "    if not line:\n",
    "        continue  # Skip empty lines\n",
    "\n",
    "    parts = line.split()  # Split line by space\n",
    "    # Extract the label, qid, and features\n",
    "    label = int(parts[0])\n",
    "    qid = int(parts[1].split(\":\")[1])\n",
    "    present_feature= []\n",
    "    for i in range(2,len(parts)):\n",
    "        present_feature.append([int(parts[i].split(\":\")[0]),float(parts[i].split(\":\")[1])])\n",
    "    #print(present_feature)\n",
    "    k=0\n",
    "    features=[]\n",
    "    for i in range(1,700):\n",
    "        if(k<len(present_feature)):\n",
    "            if(i==present_feature[k][0]):\n",
    "                features.append(present_feature[k][1])\n",
    "                k=k+1\n",
    "            else:\n",
    "                features.append(0)\n",
    "        else:\n",
    "            features.append(0)\n",
    "    #features = [float(part.split(\":\")[1]) for part in parts[2:]]\n",
    "    \n",
    "    # Append label to the label vector\n",
    "    train_label_vector.append(label)\n",
    "\n",
    "    # Append features to the feature matrix\n",
    "    train_feature_matrix.append(features)\n",
    "\n",
    "    # Append the range of documents for this query\n",
    "    train_doclist_ranges.append(len(train_label_vector))\n",
    "#print(feature_matrix[0])\n",
    "# Convert the lists to NumPy arrays (if using NumPy)\n",
    "\n",
    "import numpy as np\n",
    "train_feature_matrix = np.array(train_feature_matrix)\n",
    "train_label_vector = np.array(train_label_vector)\n",
    "train_doclist_ranges= np.array(train_doclist_ranges)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f77fc93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ltrc_yahoo/set1.test.txt') as f:\n",
    "    lines = f.readlines()\n",
    "for i in range(len(lines)):\n",
    "    lines[i]=lines[i].rstrip(lines[i][-1])\n",
    "    #print(lines[i])\n",
    "# Initialize lists to store the data\n",
    "\n",
    "test_feature_matrix = []\n",
    "test_doclist_ranges = []\n",
    "test_label_vector = []\n",
    "cc=0\n",
    "for line in lines:\n",
    "    cc=cc+1\n",
    "    if(cc>top):\n",
    "        break\n",
    "    if not line:\n",
    "        continue  # Skip empty lines\n",
    "\n",
    "    parts = line.split()  # Split line by space\n",
    "    # Extract the label, qid, and features\n",
    "    label = int(parts[0])\n",
    "    qid = int(parts[1].split(\":\")[1])\n",
    "    present_feature= []\n",
    "    for i in range(2,len(parts)):\n",
    "        present_feature.append([int(parts[i].split(\":\")[0]),float(parts[i].split(\":\")[1])])\n",
    "    #print(present_feature)\n",
    "    k=0\n",
    "    features=[]\n",
    "    for i in range(1,700):\n",
    "        if(k<len(present_feature)):\n",
    "            if(i==present_feature[k][0]):\n",
    "                features.append(present_feature[k][1])\n",
    "                k=k+1\n",
    "            else:\n",
    "                features.append(0)\n",
    "        else:\n",
    "            features.append(0)\n",
    "    #features = [float(part.split(\":\")[1]) for part in parts[2:]]\n",
    "    \n",
    "    # Append label to the label vector\n",
    "    test_label_vector.append(label)\n",
    "\n",
    "    # Append features to the feature matrix\n",
    "    test_feature_matrix.append(features)\n",
    "\n",
    "    # Append the range of documents for this query\n",
    "    test_doclist_ranges.append(len(test_label_vector))\n",
    "#print(feature_matrix[0])\n",
    "# Convert the lists to NumPy arrays (if using NumPy)\n",
    "\n",
    "import numpy as np\n",
    "test_feature_matrix = np.array(test_feature_matrix)\n",
    "test_label_vector = np.array(test_label_vector)\n",
    "test_doclist_ranges= np.array(test_doclist_ranges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "070af0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ltrc_yahoo/set1.valid.txt') as f:\n",
    "    lines = f.readlines()\n",
    "for i in range(len(lines)):\n",
    "    lines[i]=lines[i].rstrip(lines[i][-1])\n",
    "    #print(lines[i])\n",
    "# Initialize lists to store the data\n",
    "\n",
    "valid_feature_matrix = []\n",
    "valid_doclist_ranges = []\n",
    "valid_label_vector = []\n",
    "cc=0\n",
    "for line in lines:\n",
    "    cc=cc+1\n",
    "    if(cc>top):\n",
    "        break\n",
    "    if not line:\n",
    "        continue  # Skip empty lines\n",
    "\n",
    "    parts = line.split()  # Split line by space\n",
    "    # Extract the label, qid, and features\n",
    "    label = int(parts[0])\n",
    "    qid = int(parts[1].split(\":\")[1])\n",
    "    present_feature= []\n",
    "    for i in range(2,len(parts)):\n",
    "        present_feature.append([int(parts[i].split(\":\")[0]),float(parts[i].split(\":\")[1])])\n",
    "    #print(present_feature)\n",
    "    k=0\n",
    "    features=[]\n",
    "    for i in range(1,700):\n",
    "        if(k<len(present_feature)):\n",
    "            if(i==present_feature[k][0]):\n",
    "                features.append(present_feature[k][1])\n",
    "                k=k+1\n",
    "            else:\n",
    "                features.append(0)\n",
    "        else:\n",
    "            features.append(0)\n",
    "    #features = [float(part.split(\":\")[1]) for part in parts[2:]]\n",
    "    \n",
    "    # Append label to the label vector\n",
    "    valid_label_vector.append(label)\n",
    "\n",
    "    # Append features to the feature matrix\n",
    "    valid_feature_matrix.append(features)\n",
    "\n",
    "    # Append the range of documents for this query\n",
    "    valid_doclist_ranges.append(len(valid_label_vector))\n",
    "#print(feature_matrix[0])\n",
    "#Convert the lists to NumPy arrays (if using NumPy)\n",
    "\n",
    "import numpy as np\n",
    "valid_feature_matrix = np.array(valid_feature_matrix)\n",
    "valid_label_vector = np.array(valid_label_vector)\n",
    "valid_doclist_ranges= np.array(valid_doclist_ranges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d27ec6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Specify the path where you want to save the .npz file\n",
    "output_file = \"set1.binarized_purged_querynorm_filtered.npz\"\n",
    "\n",
    "# Save the arrays to the .npz file\n",
    "np.savez(output_file, train_feature_matrix=train_feature_matrix, train_label_vector=train_label_vector ,train_doclist_ranges= train_doclist_ranges,\n",
    "         test_feature_matrix=test_feature_matrix, test_label_vector=test_label_vector,test_doclist_ranges= test_doclist_ranges,\n",
    "         valid_feature_matrix=valid_feature_matrix, valid_label_vector=valid_label_vector,valid_doclist_ranges= valid_doclist_ranges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c5dd64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
