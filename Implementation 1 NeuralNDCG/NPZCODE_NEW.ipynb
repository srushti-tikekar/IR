{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1577529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c5ec0d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: 'ltrc_yahoo/set1.train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mltrc_yahoo/set1.train.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(lines)):\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: 'ltrc_yahoo/set1.train.txt'"
     ]
    }
   ],
   "source": [
    "with open('ltrc_yahoo/set1.train.txt') as f:\n",
    "    lines = f.readlines()\n",
    "for i in range(len(lines)):\n",
    "    lines[i]=lines[i].rstrip(lines[i][-1])\n",
    "    #print(lines[i])\n",
    "# Initialize lists to store the data\n",
    "\n",
    "train_feature_matrix = []\n",
    "train_doclist_ranges = []\n",
    "train_label_vector = []\n",
    "cc=0\n",
    "dist_qid=[]\n",
    "for line in lines:\n",
    "    cc=cc+1\n",
    "    if(cc>top):\n",
    "        break\n",
    "    if not line:\n",
    "        continue  # Skip empty lines\n",
    "\n",
    "    parts = line.split()  # Split line by space\n",
    "    # Extract the label, qid, and features\n",
    "    label = int(parts[0])\n",
    "    qid = int(parts[1].split(\":\")[1])\n",
    "    if(qid not in dist_qid):\n",
    "        dist_qid.append(qid)\n",
    "    present_feature= []\n",
    "    for i in range(2,len(parts)):\n",
    "        present_feature.append([int(parts[i].split(\":\")[0]),float(parts[i].split(\":\")[1])])\n",
    "    #print(present_feature)\n",
    "    k=0\n",
    "    features=[]\n",
    "    for i in range(1,700):\n",
    "        if(k<len(present_feature)):\n",
    "            if(i==present_feature[k][0]):\n",
    "                features.append(present_feature[k][1])\n",
    "                k=k+1\n",
    "            else:\n",
    "                features.append(0)\n",
    "        else:\n",
    "            features.append(0)\n",
    "    #features = [float(part.split(\":\")[1]) for part in parts[2:]]\n",
    "    \n",
    "    # Append label to the label vector\n",
    "    train_label_vector.append(label)\n",
    "\n",
    "    # Append features to the feature matrix\n",
    "    train_feature_matrix.append(features)\n",
    "\n",
    "    # Append the range of documents for this query\n",
    "    train_doclist_ranges.append(qid)\n",
    "#print(feature_matrix[0])\n",
    "# Convert the lists to NumPy arrays (if using NumPy)\n",
    "\n",
    "import numpy as np\n",
    "train_feature_matrix = np.array(train_feature_matrix)\n",
    "train_label_vector = np.array(train_label_vector)\n",
    "train_doclist_ranges= np.array(train_doclist_ranges)\n",
    "#print(train_doclist_ranges)\n",
    "dict_qid={}\n",
    "for i in range(len(dist_qid)):\n",
    "    if(dist_qid[i] not in dict_qid.keys()):\n",
    "        dict_qid[dist_qid[i]]=0\n",
    "    for j in range(len(train_doclist_ranges)):\n",
    "        if(dist_qid[i] == train_doclist_ranges[j]):\n",
    "            dict_qid[dist_qid[i]]=dict_qid[dist_qid[i]]+1\n",
    "qid_list=list(dict_qid.keys())\n",
    "n=len(qid_list)\n",
    "#print(dict_qid)\n",
    "cum_qid_dict={}\n",
    "s=0\n",
    "for j in range(n):\n",
    "    s=s+dict_qid[qid_list[j]]\n",
    "    cum_qid_dict[qid_list[j]]=s\n",
    "#print(cum_qid_dict)\n",
    "\n",
    "for j in range(len(train_doclist_ranges)):\n",
    "    train_doclist_ranges[j]=cum_qid_dict[train_doclist_ranges[j]]\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7204ebd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_doclist_ranges' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_doclist_ranges\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_doclist_ranges' is not defined"
     ]
    }
   ],
   "source": [
    "train_doclist_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3160dddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331]\n"
     ]
    }
   ],
   "source": [
    "print(dist_qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "623cdde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1,\n",
       " 2: 13,\n",
       " 3: 5,\n",
       " 4: 8,\n",
       " 5: 19,\n",
       " 6: 12,\n",
       " 7: 18,\n",
       " 8: 5,\n",
       " 9: 14,\n",
       " 10: 13,\n",
       " 11: 8,\n",
       " 12: 9,\n",
       " 13: 16,\n",
       " 14: 11,\n",
       " 15: 21,\n",
       " 16: 14,\n",
       " 17: 21,\n",
       " 18: 9,\n",
       " 19: 14,\n",
       " 20: 11,\n",
       " 21: 20,\n",
       " 22: 18,\n",
       " 23: 13,\n",
       " 24: 20,\n",
       " 25: 22,\n",
       " 26: 22,\n",
       " 27: 13,\n",
       " 28: 17,\n",
       " 29: 10,\n",
       " 30: 13,\n",
       " 31: 12,\n",
       " 32: 13,\n",
       " 33: 13,\n",
       " 34: 23,\n",
       " 35: 18,\n",
       " 36: 13,\n",
       " 37: 20,\n",
       " 38: 12,\n",
       " 39: 22,\n",
       " 40: 14,\n",
       " 41: 13,\n",
       " 42: 23,\n",
       " 43: 13,\n",
       " 44: 14,\n",
       " 45: 14,\n",
       " 46: 5,\n",
       " 47: 13,\n",
       " 48: 15,\n",
       " 49: 14,\n",
       " 50: 14,\n",
       " 51: 16,\n",
       " 52: 16,\n",
       " 53: 15,\n",
       " 54: 21,\n",
       " 55: 22,\n",
       " 56: 10,\n",
       " 57: 22,\n",
       " 58: 18,\n",
       " 59: 25,\n",
       " 60: 16,\n",
       " 61: 12,\n",
       " 62: 12,\n",
       " 63: 15,\n",
       " 64: 15,\n",
       " 65: 25,\n",
       " 66: 13,\n",
       " 67: 9,\n",
       " 68: 12,\n",
       " 69: 8,\n",
       " 70: 16,\n",
       " 71: 25,\n",
       " 72: 19,\n",
       " 73: 24,\n",
       " 74: 12,\n",
       " 75: 16,\n",
       " 76: 10,\n",
       " 77: 16,\n",
       " 78: 9,\n",
       " 79: 17,\n",
       " 80: 15,\n",
       " 81: 7,\n",
       " 82: 9,\n",
       " 83: 15,\n",
       " 84: 14,\n",
       " 85: 16,\n",
       " 86: 17,\n",
       " 87: 8,\n",
       " 88: 17,\n",
       " 89: 12,\n",
       " 90: 18,\n",
       " 91: 23,\n",
       " 92: 10,\n",
       " 93: 12,\n",
       " 94: 12,\n",
       " 95: 4,\n",
       " 96: 14,\n",
       " 97: 12,\n",
       " 98: 15,\n",
       " 99: 27,\n",
       " 100: 16,\n",
       " 101: 20,\n",
       " 102: 13,\n",
       " 103: 19,\n",
       " 104: 13,\n",
       " 105: 17,\n",
       " 106: 17,\n",
       " 107: 16,\n",
       " 108: 12,\n",
       " 109: 15,\n",
       " 110: 14,\n",
       " 111: 14,\n",
       " 112: 19,\n",
       " 113: 12,\n",
       " 114: 23,\n",
       " 115: 18,\n",
       " 116: 16,\n",
       " 117: 9,\n",
       " 118: 23,\n",
       " 119: 11,\n",
       " 120: 15,\n",
       " 121: 8,\n",
       " 122: 10,\n",
       " 123: 10,\n",
       " 124: 16,\n",
       " 125: 11,\n",
       " 126: 15,\n",
       " 127: 22,\n",
       " 128: 16,\n",
       " 129: 17,\n",
       " 130: 23,\n",
       " 131: 16,\n",
       " 132: 22,\n",
       " 133: 17,\n",
       " 134: 14,\n",
       " 135: 12,\n",
       " 136: 14,\n",
       " 137: 20,\n",
       " 138: 15,\n",
       " 139: 17,\n",
       " 140: 15,\n",
       " 141: 15,\n",
       " 142: 22,\n",
       " 143: 9,\n",
       " 144: 21,\n",
       " 145: 9,\n",
       " 146: 17,\n",
       " 147: 16,\n",
       " 148: 15,\n",
       " 149: 13,\n",
       " 150: 13,\n",
       " 151: 15,\n",
       " 152: 14,\n",
       " 153: 18,\n",
       " 154: 21,\n",
       " 155: 14,\n",
       " 156: 17,\n",
       " 157: 15,\n",
       " 158: 14,\n",
       " 159: 16,\n",
       " 160: 12,\n",
       " 161: 17,\n",
       " 162: 19,\n",
       " 163: 16,\n",
       " 164: 11,\n",
       " 165: 18,\n",
       " 166: 11,\n",
       " 167: 13,\n",
       " 168: 14,\n",
       " 169: 9,\n",
       " 170: 16,\n",
       " 171: 15,\n",
       " 172: 16,\n",
       " 173: 25,\n",
       " 174: 9,\n",
       " 175: 13,\n",
       " 176: 22,\n",
       " 177: 16,\n",
       " 178: 18,\n",
       " 179: 20,\n",
       " 180: 14,\n",
       " 181: 11,\n",
       " 182: 9,\n",
       " 183: 16,\n",
       " 184: 19,\n",
       " 185: 19,\n",
       " 186: 11,\n",
       " 187: 11,\n",
       " 188: 13,\n",
       " 189: 14,\n",
       " 190: 14,\n",
       " 191: 13,\n",
       " 192: 16,\n",
       " 193: 6,\n",
       " 194: 21,\n",
       " 195: 16,\n",
       " 196: 12,\n",
       " 197: 16,\n",
       " 198: 11,\n",
       " 199: 24,\n",
       " 200: 12,\n",
       " 201: 10,\n",
       " 202: 12,\n",
       " 203: 19,\n",
       " 204: 18,\n",
       " 205: 10,\n",
       " 206: 15,\n",
       " 207: 15,\n",
       " 208: 22,\n",
       " 209: 23,\n",
       " 210: 18,\n",
       " 211: 16,\n",
       " 212: 16,\n",
       " 213: 11,\n",
       " 214: 6,\n",
       " 215: 13,\n",
       " 216: 17,\n",
       " 217: 21,\n",
       " 218: 20,\n",
       " 219: 16,\n",
       " 220: 13,\n",
       " 221: 16,\n",
       " 222: 21,\n",
       " 223: 15,\n",
       " 224: 10,\n",
       " 225: 19,\n",
       " 226: 10,\n",
       " 227: 13,\n",
       " 228: 18,\n",
       " 229: 17,\n",
       " 230: 23,\n",
       " 231: 24,\n",
       " 232: 16,\n",
       " 233: 13,\n",
       " 234: 17,\n",
       " 235: 24,\n",
       " 236: 17,\n",
       " 237: 10,\n",
       " 238: 17,\n",
       " 239: 15,\n",
       " 240: 18,\n",
       " 241: 16,\n",
       " 242: 9,\n",
       " 243: 9,\n",
       " 244: 21,\n",
       " 245: 14,\n",
       " 246: 13,\n",
       " 247: 13,\n",
       " 248: 13,\n",
       " 249: 10,\n",
       " 250: 10,\n",
       " 251: 6,\n",
       " 252: 16,\n",
       " 253: 14,\n",
       " 254: 16,\n",
       " 255: 20,\n",
       " 256: 14,\n",
       " 257: 16,\n",
       " 258: 21,\n",
       " 259: 11,\n",
       " 260: 16,\n",
       " 261: 20,\n",
       " 262: 16,\n",
       " 263: 12,\n",
       " 264: 19,\n",
       " 265: 12,\n",
       " 266: 19,\n",
       " 267: 20,\n",
       " 268: 25,\n",
       " 269: 21,\n",
       " 270: 19,\n",
       " 271: 21,\n",
       " 272: 19,\n",
       " 273: 16,\n",
       " 274: 13,\n",
       " 275: 12,\n",
       " 276: 17,\n",
       " 277: 20,\n",
       " 278: 15,\n",
       " 279: 13,\n",
       " 280: 14,\n",
       " 281: 20,\n",
       " 282: 23,\n",
       " 283: 10,\n",
       " 284: 17,\n",
       " 285: 11,\n",
       " 286: 9,\n",
       " 287: 23,\n",
       " 288: 8,\n",
       " 289: 14,\n",
       " 290: 14,\n",
       " 291: 15,\n",
       " 292: 12,\n",
       " 293: 12,\n",
       " 294: 13,\n",
       " 295: 16,\n",
       " 296: 9,\n",
       " 297: 8,\n",
       " 298: 9,\n",
       " 299: 19,\n",
       " 300: 16,\n",
       " 301: 16,\n",
       " 302: 19,\n",
       " 303: 12,\n",
       " 304: 15,\n",
       " 305: 14,\n",
       " 306: 16,\n",
       " 307: 19,\n",
       " 308: 8,\n",
       " 309: 8,\n",
       " 310: 13,\n",
       " 311: 12,\n",
       " 312: 19,\n",
       " 313: 29,\n",
       " 314: 8,\n",
       " 315: 16,\n",
       " 316: 16,\n",
       " 317: 22,\n",
       " 318: 12,\n",
       " 319: 13,\n",
       " 320: 18,\n",
       " 321: 9,\n",
       " 322: 13,\n",
       " 323: 15,\n",
       " 324: 20,\n",
       " 325: 16,\n",
       " 326: 19,\n",
       " 327: 10,\n",
       " 328: 19,\n",
       " 329: 9,\n",
       " 330: 14,\n",
       " 331: 13}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_qid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f77fc93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{22939: 23, 22940: 37, 22941: 57, 22942: 79, 22943: 93, 22944: 102, 22945: 120, 22946: 129, 22947: 143, 22948: 151, 22949: 167, 22950: 186, 22951: 197, 22952: 217, 22953: 231, 22954: 246, 22955: 254, 22956: 271, 22957: 279, 22958: 294, 22959: 311, 22960: 326, 22961: 343, 22962: 362, 22963: 378, 22964: 395, 22965: 413, 22966: 434, 22967: 448, 22968: 462, 22969: 473, 22970: 496, 22971: 503, 22972: 521, 22973: 535, 22974: 552, 22975: 566, 22976: 588, 22977: 599, 22978: 610, 22979: 629, 22980: 647, 22981: 653, 22982: 676, 22983: 694, 22984: 708, 22985: 719, 22986: 736, 22987: 752, 22988: 767, 22989: 788, 22990: 803, 22991: 813, 22992: 826, 22993: 843, 22994: 868, 22995: 891, 22996: 912, 22997: 924, 22998: 935, 22999: 954, 23000: 965, 23001: 981, 23002: 996, 23003: 1018, 23004: 1030, 23005: 1045, 23006: 1066, 23007: 1079, 23008: 1095, 23009: 1111, 23010: 1127, 23011: 1142, 23012: 1159, 23013: 1172, 23014: 1195, 23015: 1210, 23016: 1232, 23017: 1243, 23018: 1261, 23019: 1280, 23020: 1291, 23021: 1317, 23022: 1340, 23023: 1359, 23024: 1373, 23025: 1386, 23026: 1398, 23027: 1409, 23028: 1430, 23029: 1455, 23030: 1473, 23031: 1491, 23032: 1509, 23033: 1525, 23034: 1543, 23035: 1561, 23036: 1569, 23037: 1585, 23038: 1611, 23039: 1629, 23040: 1630, 23041: 1650, 23042: 1666, 23043: 1687, 23044: 1706, 23045: 1719, 23046: 1734, 23047: 1750, 23048: 1766, 23049: 1781, 23050: 1797, 23051: 1810, 23052: 1822, 23053: 1838, 23054: 1856, 23055: 1864, 23056: 1886, 23057: 1897, 23058: 1910, 23059: 1928, 23060: 1946, 23061: 1964, 23062: 1987, 23063: 2005, 23064: 2012, 23065: 2023, 23066: 2034, 23067: 2041, 23068: 2064, 23069: 2074, 23070: 2088, 23071: 2108, 23072: 2117, 23073: 2128, 23074: 2139, 23075: 2157, 23076: 2174, 23077: 2187, 23078: 2206, 23079: 2219, 23080: 2229, 23081: 2245, 23082: 2264, 23083: 2286, 23084: 2299, 23085: 2318, 23086: 2332, 23087: 2353, 23088: 2369, 23089: 2381, 23090: 2396, 23091: 2417, 23092: 2431, 23093: 2441, 23094: 2463, 23095: 2479, 23096: 2498, 23097: 2517, 23098: 2533, 23099: 2547, 23100: 2563, 23101: 2574, 23102: 2593, 23103: 2595, 23104: 2613, 23105: 2623, 23106: 2637, 23107: 2654, 23108: 2673, 23109: 2691, 23110: 2711, 23111: 2729, 23112: 2748, 23113: 2769, 23114: 2787, 23115: 2813, 23116: 2835, 23117: 2851, 23118: 2867, 23119: 2885, 23120: 2901, 23121: 2914, 23122: 2933, 23123: 2949, 23124: 2965, 23125: 2977, 23126: 2991, 23127: 3011, 23128: 3020, 23129: 3031, 23130: 3046, 23131: 3055, 23132: 3078, 23133: 3095, 23134: 3117, 23135: 3134, 23136: 3159, 23137: 3178, 23138: 3191, 23139: 3208, 23140: 3221, 23141: 3236, 23142: 3258, 23143: 3278, 23144: 3296, 23145: 3313, 23146: 3338, 23147: 3348, 23148: 3361, 23149: 3374, 23150: 3385, 23151: 3398, 23152: 3410, 23153: 3426, 23154: 3449, 23155: 3470, 23156: 3489, 23157: 3515, 23158: 3535, 23159: 3544, 23160: 3565, 23161: 3583, 23162: 3602, 23163: 3621, 23164: 3639, 23165: 3659, 23166: 3670, 23167: 3678, 23168: 3697, 23169: 3710, 23170: 3728, 23171: 3737, 23172: 3753, 23173: 3768, 23174: 3777, 23175: 3787, 23176: 3808, 23177: 3827, 23178: 3839, 23179: 3851, 23180: 3865, 23181: 3879, 23182: 3892, 23183: 3904, 23184: 3914, 23185: 3932, 23186: 3950, 23187: 3960, 23188: 3980, 23189: 3993, 23190: 4019, 23191: 4037, 23192: 4051, 23193: 4061, 23194: 4091, 23195: 4110, 23196: 4120, 23197: 4124, 23198: 4138, 23199: 4155, 23200: 4168, 23201: 4185, 23202: 4198, 23203: 4218, 23204: 4237, 23205: 4251, 23206: 4268, 23207: 4291, 23208: 4305, 23209: 4322, 23210: 4338, 23211: 4359, 23212: 4380, 23213: 4397, 23214: 4413, 23215: 4431, 23216: 4451, 23217: 4467, 23218: 4482, 23219: 4495, 23220: 4508, 23221: 4523, 23222: 4540, 23223: 4552, 23224: 4564, 23225: 4582, 23226: 4598, 23227: 4615, 23228: 4632, 23229: 4644, 23230: 4662, 23231: 4679, 23232: 4695, 23233: 4713, 23234: 4727, 23235: 4746, 23236: 4761, 23237: 4774, 23238: 4785, 23239: 4803, 23240: 4826, 23241: 4843, 23242: 4854, 23243: 4871, 23244: 4888, 23245: 4901, 23246: 4912, 23247: 4928, 23248: 4944, 23249: 4951, 23250: 4974, 23251: 4991, 23252: 5000}\n"
     ]
    }
   ],
   "source": [
    "with open('ltrc_yahoo/set1.test.txt') as f:\n",
    "    lines = f.readlines()\n",
    "for i in range(len(lines)):\n",
    "    lines[i]=lines[i].rstrip(lines[i][-1])\n",
    "    #print(lines[i])\n",
    "# Initialize lists to store the data\n",
    "\n",
    "test_feature_matrix = []\n",
    "test_doclist_ranges = []\n",
    "test_label_vector = []\n",
    "cc=0\n",
    "dist_qid=[]\n",
    "for line in lines:\n",
    "    cc=cc+1\n",
    "    if(cc>top):\n",
    "        break\n",
    "    if not line:\n",
    "        continue  # Skip empty lines\n",
    "\n",
    "    parts = line.split()  # Split line by space\n",
    "    # Extract the label, qid, and features\n",
    "    label = int(parts[0])\n",
    "    qid = int(parts[1].split(\":\")[1])\n",
    "    if(qid not in dist_qid):\n",
    "        dist_qid.append(qid)\n",
    "    present_feature= []\n",
    "    for i in range(2,len(parts)):\n",
    "        present_feature.append([int(parts[i].split(\":\")[0]),float(parts[i].split(\":\")[1])])\n",
    "    #print(present_feature)\n",
    "    k=0\n",
    "    features=[]\n",
    "    for i in range(1,700):\n",
    "        if(k<len(present_feature)):\n",
    "            if(i==present_feature[k][0]):\n",
    "                features.append(present_feature[k][1])\n",
    "                k=k+1\n",
    "            else:\n",
    "                features.append(0)\n",
    "        else:\n",
    "            features.append(0)\n",
    "    #features = [float(part.split(\":\")[1]) for part in parts[2:]]\n",
    "    \n",
    "    # Append label to the label vector\n",
    "    test_label_vector.append(label)\n",
    "\n",
    "    # Append features to the feature matrix\n",
    "    test_feature_matrix.append(features)\n",
    "\n",
    "    # Append the range of documents for this query\n",
    "    test_doclist_ranges.append(qid)\n",
    "#print(feature_matrix[0])\n",
    "# Convert the lists to NumPy arrays (if using NumPy)\n",
    "\n",
    "import numpy as np\n",
    "test_feature_matrix = np.array(test_feature_matrix)\n",
    "test_label_vector = np.array(test_label_vector)\n",
    "test_doclist_ranges= np.array(test_doclist_ranges)\n",
    "#print(test_doclist_ranges)\n",
    "dict_qid={}\n",
    "for i in range(len(dist_qid)):\n",
    "    if(dist_qid[i] not in dict_qid.keys()):\n",
    "        dict_qid[dist_qid[i]]=0\n",
    "    for j in range(len(test_doclist_ranges)):\n",
    "        if(dist_qid[i] == test_doclist_ranges[j]):\n",
    "            dict_qid[dist_qid[i]]=dict_qid[dist_qid[i]]+1\n",
    "qid_list=list(dict_qid.keys())\n",
    "n=len(qid_list)\n",
    "#print(dict_qid)\n",
    "cum_qid_dict={}\n",
    "s=0\n",
    "for j in range(n):\n",
    "    s=s+dict_qid[qid_list[j]]\n",
    "    cum_qid_dict[qid_list[j]]=s\n",
    "print(cum_qid_dict)\n",
    "\n",
    "for j in range(len(test_doclist_ranges)):\n",
    "    test_doclist_ranges[j]=cum_qid_dict[test_doclist_ranges[j]]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "391b37eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.74142  0.       0.       ... 0.046567 0.       0.11245 ]\n",
      " [0.       0.       0.       ... 0.046567 0.86567  0.10183 ]\n",
      " [0.       0.       0.       ... 0.046567 0.61889  0.77157 ]\n",
      " ...\n",
      " [0.       0.       0.       ... 0.046567 0.       0.97348 ]\n",
      " [0.       0.       0.       ... 0.046567 0.       0.85936 ]\n",
      " [0.       0.       0.       ... 0.046567 0.       0.97696 ]]\n"
     ]
    }
   ],
   "source": [
    "print(test_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "978eec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_label_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a2e277f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  23,   23,   23, ..., 5000, 5000, 5000])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doclist_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "070af0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ltrc_yahoo/set1.valid.txt') as f:\n",
    "    lines = f.readlines()\n",
    "for i in range(len(lines)):\n",
    "    lines[i]=lines[i].rstrip(lines[i][-1])\n",
    "    #print(lines[i])\n",
    "# Initialize lists to store the data\n",
    "\n",
    "valid_feature_matrix = []\n",
    "valid_doclist_ranges = []\n",
    "valid_label_vector = []\n",
    "cc=0\n",
    "dist_qid=[]\n",
    "for line in lines:\n",
    "    cc=cc+1\n",
    "    if(cc>top):\n",
    "        break\n",
    "    if not line:\n",
    "        continue  # Skip empty lines\n",
    "\n",
    "    parts = line.split()  # Split line by space\n",
    "    # Extract the label, qid, and features\n",
    "    label = int(parts[0])\n",
    "    qid = int(parts[1].split(\":\")[1])\n",
    "    if(qid not in dist_qid):\n",
    "        dist_qid.append(qid)\n",
    "    present_feature= []\n",
    "    for i in range(2,len(parts)):\n",
    "        present_feature.append([int(parts[i].split(\":\")[0]),float(parts[i].split(\":\")[1])])\n",
    "    #print(present_feature)\n",
    "    k=0\n",
    "    features=[]\n",
    "    for i in range(1,700):\n",
    "        if(k<len(present_feature)):\n",
    "            if(i==present_feature[k][0]):\n",
    "                features.append(present_feature[k][1])\n",
    "                k=k+1\n",
    "            else:\n",
    "                features.append(0)\n",
    "        else:\n",
    "            features.append(0)\n",
    "    #features = [float(part.split(\":\")[1]) for part in parts[2:]]\n",
    "    \n",
    "    # Append label to the label vector\n",
    "    valid_label_vector.append(label)\n",
    "\n",
    "    # Append features to the feature matrix\n",
    "    valid_feature_matrix.append(features)\n",
    "\n",
    "    # Append the range of documents for this query\n",
    "    valid_doclist_ranges.append(qid)\n",
    "#print(feature_matrix[0])\n",
    "#Convert the lists to NumPy arrays (if using NumPy)\n",
    "\n",
    "import numpy as np\n",
    "valid_feature_matrix = np.array(valid_feature_matrix)\n",
    "valid_label_vector = np.array(valid_label_vector)\n",
    "valid_doclist_ranges= np.array(valid_doclist_ranges)\n",
    "#print(valid_doclist_ranges)\n",
    "\n",
    "dict_qid={}\n",
    "for i in range(len(dist_qid)):\n",
    "    if(dist_qid[i] not in dict_qid.keys()):\n",
    "        dict_qid[dist_qid[i]]=0\n",
    "    for j in range(len(valid_doclist_ranges)):\n",
    "        if(dist_qid[i] == valid_doclist_ranges[j]):\n",
    "            dict_qid[dist_qid[i]]=dict_qid[dist_qid[i]]+1\n",
    "qid_list=list(dict_qid.keys())\n",
    "n=len(qid_list)\n",
    "#print(dict_qid)\n",
    "\n",
    "cum_qid_dict={}\n",
    "s=0\n",
    "for j in range(n):\n",
    "    s=s+dict_qid[qid_list[j]]\n",
    "    cum_qid_dict[qid_list[j]]=s\n",
    "#print(cum_qid_dict)\n",
    "\n",
    "for j in range(len(valid_doclist_ranges)):\n",
    "    valid_doclist_ranges[j]=cum_qid_dict[valid_doclist_ranges[j]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "49992ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  18,   18,   18, ..., 5000, 5000, 5000])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_doclist_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d27ec6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Specify the path where you want to save the .npz file\n",
    "output_file = \"set1.binarized_purged_querynorm_filtered.npz\"\n",
    "\n",
    "# Save the arrays to the .npz file\n",
    "np.savez(output_file, train_feature_matrix=train_feature_matrix, train_label_vector=train_label_vector ,train_doclist_ranges= train_doclist_ranges,\n",
    "         test_feature_matrix=test_feature_matrix, test_label_vector=test_label_vector,test_doclist_ranges= test_doclist_ranges,\n",
    "         valid_feature_matrix=valid_feature_matrix, valid_label_vector=valid_label_vector,valid_doclist_ranges= valid_doclist_ranges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c5dd64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8fa969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
