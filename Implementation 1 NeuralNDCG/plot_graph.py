# -*- coding: utf-8 -*-
"""plot_graph.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zxW8Vz3OWwXjnKE0HKB_89kzvH79dkSc
"""

import matplotlib.pyplot as plt

# Simulated training, validation, and test accuracy and loss values
# Replace these lists with your actual data
epochs = [1, 2, 3, 4, 5]
train_accuracy = [0.6, 0.7, 0.8, 0.85, 0.9]
validation_accuracy = [0.55, 0.65, 0.75, 0.8, 0.85]
test_accuracy = [0.58, 0.68, 0.78, 0.82, 0.87]
loss = [1.2, 0.9, 0.7, 0.6, 0.5]
def plot_graphs(epochs, train_acc, val_acc, loss, loss_fn_name):


# Provided data
#train_acc = [0.7446246520723036, 0.7475306391694665, 0.7634898602945693, 0.7639228440056781, 0.7756304565056293, 0.7770653928937992, 0.7731445615846054, 0.769138068538158, 0.7614352791576573, 0.777001915614483]
#val_acc = [0.42439383891346827, 0.5434594857829493, 0.6354087647401883, 0.6341117318632815, 0.5831604247869789, 0.5960718173680886, 0.6237683600846946, 0.5939516600699908, 0.609303701899909, 0.6545813508446043]
#loss = [0.7265568324171316, 0.7166882755403015, 0.7093899278699418, 0.7053555055761969, 0.7035825273275219, 0.7015349216206105, 0.7008074562942687, 0.7001547683523531, 0.6994430916501923, 0.698805009732799]
#epochs = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

# Plot training accuracy, validation accuracy, and loss
    plt.figure(figsize=(10, 5))

# Training and validation accuracy
    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_acc, label='Training NDCG', marker='o')
    plt.plot(epochs, val_acc, label='Validation NDCG', marker='x')
    plt.xlabel('Epochs')
    plt.ylabel('NDCG')
    plt.title('Training and Validation NDCG')
    plt.legend()
    plt.grid()

# Loss
    plt.subplot(1, 2, 2)
    plt.plot(epochs, loss, label='Loss', marker='o', color='red')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Loss')
    plt.legend()
    plt.grid()

#plt.tight_layout()

# Show the plots
    plt.show()

    plt.savefig('plot.png')

def plot_graphs_new(epochs, train_ndcg, val_ndcg, test_ndcg, loss, loss_fn_name):
    # Plot training and validation NDCG, and loss
    plt.figure(figsize=(15, 5))

    # Training and validation NDCG
    plt.subplot(1, 3, 1)
    plt.plot(epochs, train_ndcg, label='Training NDCG', marker='o')
    plt.plot(epochs, val_ndcg, label='Validation NDCG', marker='x')
    plt.plot(epochs, test_ndcg, label='Test NDCG', marker='s')
    plt.xlabel('Epochs')
    plt.ylabel('NDCG')
    plt.title('Training, Validation, and Test NDCG')
    plt.legend()
    plt.grid()

    # Loss
    plt.subplot(1, 3, 2)
    plt.plot(epochs, loss, label='Loss', marker='o', color='red')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Loss')
    plt.legend()
    plt.grid()

    # Save the plots
    plt.tight_layout()
    plt.savefig('plot-1.png')

    # Show the plots
    plt.show()

epochs = [1, 2, 3, 4, 5]
train_accuracy = [0.6, 0.7, 0.8, 0.85, 0.9]
validation_accuracy = [0.55, 0.65, 0.75, 0.8, 0.85]
test_accuracy = [0.58, 0.68, 0.78, 0.82, 0.87]
loss = [1.2, 0.9, 0.7, 0.6, 0.5]
loss_fn_name = "Lambda"
plot_graphs(epochs, train_accuracy, validation_accuracy, loss, loss_fn_name)